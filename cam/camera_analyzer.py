# camera_analyzer.py
import cv2
import numpy as np
from datetime import datetime
import requests

import json
import base64
import os

class PersonAnalyzer:
    def __init__(self):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞—Å–∫–∞–¥–æ–≤ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        self.body_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_fullbody.xml')
        
        # URL –≤–∞—à–µ–≥–æ Flask API
        self.api_url = "http://localhost:5000/api/analyze"
    
    def detect_gender(self, face_roi):
        """
        –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≥–µ–Ω–¥–µ—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–º–µ—Ä–æ–≤ –ª–∏—Ü–∞
        –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ (dlib, OpenCV DNN)
        """
        height, width = face_roi.shape[:2]
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–∞ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        ratio = width / height
        if ratio > 0.8:
            return "male", 0.6
        else:
            return "female", 0.6
    
    def analyze_clothing(self, body_roi):
        """
        –ê–Ω–∞–ª–∏–∑ –æ–¥–µ–∂–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ü–≤–µ—Ç–æ–≤—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
        –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ CNN –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ–¥–µ–∂–¥—ã
        """
        if body_roi is None or body_roi.size == 0:
            return "unknown", 0.0
        
        # –ê–Ω–∞–ª–∏–∑ –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏—Ö —Ü–≤–µ—Ç–æ–≤
        colors = cv2.mean(body_roi)[:3]
        
        # –ü—Ä–æ—Å—Ç–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ —Ü–≤–µ—Ç—É (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–∞ CNN)
        if colors[2] > colors[1] and colors[2] > colors[0]:  # –ö—Ä–∞—Å–Ω—ã–π –∫–∞–Ω–∞–ª
            clothing_type = "red_clothing"
        elif colors[1] > colors[0] and colors[1] > colors[2]:  # –ó–µ–ª–µ–Ω—ã–π –∫–∞–Ω–∞–ª
            clothing_type = "casual_wear"
        elif colors[0] > colors[1] and colors[0] > colors[2]:  # –°–∏–Ω–∏–π –∫–∞–Ω–∞–ª
            clothing_type = "formal_wear"
        else:
            clothing_type = "mixed_clothing"
        
        return clothing_type, 0.7
    
    def send_to_api(self, data):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ Flask API"""
        try:
            response = requests.post(self.api_url, json=data, timeout=5)
            if response.status_code == 200:
                print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã: {response.json()}")
                return True
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ API: {response.status_code}")
                return False
        except requests.exceptions.RequestException as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {e}")
            return False
    
    def encode_image(self, image):
        """–ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ base64"""
        _, buffer = cv2.imencode('.jpg', image)
        return base64.b64encode(buffer).decode('utf-8')
    
    def analyze_frame(self, frame):
        """–ê–Ω–∞–ª–∏–∑ –∫–∞–¥—Ä–∞ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü
        faces = self.face_cascade.detectMultiScale(
            gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)
        )
        
        # –î–µ—Ç–µ–∫—Ü–∏—è —Ç–µ–ª (–¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ–¥–µ–∂–¥—ã)
        bodies = self.body_cascade.detectMultiScale(
            gray, scaleFactor=1.1, minNeighbors=3, minSize=(50, 100)
        )
        
        results = []
        
        for i, (x, y, w, h) in enumerate(faces):
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–±–ª–∞—Å—Ç–∏ –ª–∏—Ü–∞
            face_roi = gray[y:y+h, x:x+w]
            face_color = frame[y:y+h, x:x+w]
            
            # –ê–Ω–∞–ª–∏–∑ –≥–µ–Ω–¥–µ—Ä–∞
            gender, gender_confidence = self.detect_gender(face_roi)
            
            # –ü–æ–∏—Å–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ —Ç–µ–ª–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ–¥–µ–∂–¥—ã
            clothing_type, clothing_confidence = "unknown", 0.0
            body_roi = None
            
            for (bx, by, bw, bh) in bodies:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ª–∏—Ü–æ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –≤–µ—Ä—Ö–Ω–µ–π —á–∞—Å—Ç–∏ —Ç–µ–ª–∞
                if (x >= bx and x + w <= bx + bw and 
                    y >= by and y <= by + bh // 3):
                    body_roi = frame[by:by+bh, bx:bx+bw]
                    clothing_type, clothing_confidence = self.analyze_clothing(body_roi)
                    break
            
            # –†–∏—Å–æ–≤–∞–Ω–∏–µ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–æ–≤
            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            info_text = f"Gender: {gender} ({gender_confidence:.2f})"
            cv2.putText(frame, info_text, (x, y-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)
            
            clothing_text = f"Clothing: {clothing_type}"
            cv2.putText(frame, clothing_text, (x, y+h+20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è API
            person_data = {
                "id": f"person_{i}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "timestamp": datetime.now().isoformat(),
                "face_coordinates": {"x": int(x), "y": int(y), "width": int(w), "height": int(h)},
                "gender": {
                    "prediction": gender,
                    "confidence": float(gender_confidence)
                },
                "clothing": {
                    "type": clothing_type,
                    "confidence": float(clothing_confidence)
                },
                "face_image": self.encode_image(face_color) if face_color.size > 0 else None
            }
            
            results.append(person_data)
        
        return frame, results
    
    def start_capture(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –∑–∞—Ö–≤–∞—Ç–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞"""
        camera = cv2.VideoCapture(0)
        
        if not camera.isOpened():
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É")
            return
        
        print("üé• –ö–∞–º–µ—Ä–∞ –∑–∞–ø—É—â–µ–Ω–∞. –ù–∞–∂–º–∏—Ç–µ 'q' –¥–ª—è –≤—ã—Ö–æ–¥–∞, 's' –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–∞–¥—Ä–∞ –≤ –ë–î")
        
        frame_count = 0
        save_next = False
        
        while True:
            ret, frame = camera.read()
            if not ret:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–∞–¥—Ä")
                break
            
            # –ê–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ 10-–≥–æ –∫–∞–¥—Ä–∞ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            if frame_count % 10 == 0 or save_next:
                analyzed_frame, results = self.analyze_frame(frame.copy())
                
                # –û—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ API –ø—Ä–∏ –Ω–∞–∂–∞—Ç–∏–∏ 's' –∏–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
                if save_next and results:
                    for person_data in results:
                        self.send_to_api(person_data)
                    save_next = False
                
                cv2.imshow('Person Analyzer', analyzed_frame)
            else:
                cv2.imshow('Person Analyzer', frame)
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª–∞–≤–∏—à
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('s'):
                save_next = True
                print("üì∏ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Å–ª–µ–¥—É—é—â–µ–º –∫–∞–¥—Ä–µ...")
            
            frame_count += 1
        
        camera.release()
        cv2.destroyAllWindows()
        print("üëã –ö–∞–º–µ—Ä–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")


# flask_app.py
from flask import Flask, request, jsonify
from flask_sqlalchemy import SQLAlchemy
from datetime import datetime
import json

app = Flask(__name__)
app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///person_data.db'
app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False

db = SQLAlchemy(app)

# –ú–æ–¥–µ–ª—å –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
class PersonDetection(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    person_id = db.Column(db.String(100), nullable=False)
    timestamp = db.Column(db.DateTime, default=datetime.utcnow)
    
    # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –ª–∏—Ü–∞
    face_x = db.Column(db.Integer)
    face_y = db.Column(db.Integer)
    face_width = db.Column(db.Integer)
    face_height = db.Column(db.Integer)
    
    # –î–∞–Ω–Ω—ã–µ –æ –≥–µ–Ω–¥–µ—Ä–µ
    gender = db.Column(db.String(20))
    gender_confidence = db.Column(db.Float)
    
    # –î–∞–Ω–Ω—ã–µ –æ–± –æ–¥–µ–∂–¥–µ
    clothing_type = db.Column(db.String(50))
    clothing_confidence = db.Column(db.Float)
    
    # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ª–∏—Ü–∞ (base64)
    face_image = db.Column(db.Text)
    
    def to_dict(self):
        return {
            'id': self.id,
            'person_id': self.person_id,
            'timestamp': self.timestamp.isoformat(),
            'face_coordinates': {
                'x': self.face_x,
                'y': self.face_y,
                'width': self.face_width,
                'height': self.face_height
            },
            'gender': {
                'prediction': self.gender,
                'confidence': self.gender_confidence
            },
            'clothing': {
                'type': self.clothing_type,
                'confidence': self.clothing_confidence
            }
        }

@app.route('/api/analyze', methods=['POST'])
def analyze_person():
    try:
        data = request.get_json()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –≤ –ë–î
        detection = PersonDetection(
            person_id=data['id'],
            face_x=data['face_coordinates']['x'],
            face_y=data['face_coordinates']['y'],
            face_width=data['face_coordinates']['width'],
            face_height=data['face_coordinates']['height'],
            gender=data['gender']['prediction'],
            gender_confidence=data['gender']['confidence'],
            clothing_type=data['clothing']['type'],
            clothing_confidence=data['clothing']['confidence'],
            face_image=data.get('face_image')
        )
        
        db.session.add(detection)
        db.session.commit()
        
        return jsonify({
            'status': 'success',
            'message': 'Person data saved successfully',
            'id': detection.id
        }), 200
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 400

@app.route('/api/detections', methods=['GET'])
def get_detections():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–µ—Ç–µ–∫—Ü–∏–π"""
    detections = PersonDetection.query.order_by(PersonDetection.timestamp.desc()).all()
    return jsonify([detection.to_dict() for detection in detections])

@app.route('/api/stats', methods=['GET'])
def get_stats():
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–µ—Ç–µ–∫—Ü–∏—è–º"""
    total = PersonDetection.query.count()
    male_count = PersonDetection.query.filter_by(gender='male').count()
    female_count = PersonDetection.query.filter_by(gender='female').count()
    
    clothing_stats = db.session.query(
        PersonDetection.clothing_type,
        db.func.count(PersonDetection.clothing_type)
    ).group_by(PersonDetection.clothing_type).all()
    
    return jsonify({
        'total_detections': total,
        'gender_distribution': {
            'male': male_count,
            'female': female_count
        },
        'clothing_distribution': dict(clothing_stats)
    })

if __name__ == '__main__':
    with app.app_context():
        db.create_all()
    
    print("üöÄ Flask API –∑–∞–ø—É—â–µ–Ω –Ω–∞ http://localhost:5000")
    print("üìä –î–æ—Å—Ç—É–ø–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã:")
    print("  POST /api/analyze - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –ø–µ—Ä—Å–æ–Ω–µ")
    print("  GET /api/detections - –ø–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–µ—Ç–µ–∫—Ü–∏–π")
    print("  GET /api/stats - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
    
    app.run(debug=True, port=5000)


# run_camera.py - –∑–∞–ø—É—Å–∫ —Ç–æ–ª—å–∫–æ –∫–∞–º–µ—Ä—ã
if __name__ == '__main__':
    print("üé• –ó–∞–ø—É—Å–∫ –∫–∞–º–µ—Ä—ã –∞–Ω–∞–ª–∏–∑–∞ –ø–µ—Ä—Å–æ–Ω")
    print("üìã –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Flask API –∑–∞–ø—É—â–µ–Ω –Ω–∞ localhost:5000")
    print("‚å®Ô∏è  –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ:")
    print("   's' - —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ –ë–î")
    print("   'q' - –≤—ã–π—Ç–∏")
    
    analyzer = PersonAnalyzer()
    analyzer.start_capture()


